{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import variational_bayes as vb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "import scipy.stats\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import metrics\n",
    "import multiprocessing\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams['figure.dpi'] = 144\n",
    "rcParams['scatter.marker'] = '.'\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableAccessor:\n",
    "    def __init__(self, iterable):\n",
    "        self._iterable = iterable\n",
    "        \n",
    "    def __getitem__(self, y):\n",
    "        return [item[y] for item in self._iterable]\n",
    "    \n",
    "accessor = IterableAccessor([{'a': 1}, {'a': 2}])\n",
    "accessor['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(np.random.normal(0, 1, (num_samples//2, size)))\n",
    "np.testing.assert_allclose(cov, cov.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sizes = [20, 50, 100]\n",
    "for size in list_sizes:\n",
    "    list_fraction = np.linspace(0.9, 1.1, 21)\n",
    "    list_num_samples = list_fraction * size\n",
    "    num_runs = 100\n",
    "    pd = []\n",
    "    for num_samples in list_num_samples:\n",
    "        num_samples = int(num_samples)\n",
    "        pd.append([vb.is_positive_definite(np.cov(np.random.normal(0, 1, (num_samples, size)), rowvar=False))\n",
    "                   for _ in range(num_runs)])\n",
    "\n",
    "    plt.errorbar(list_fraction, np.mean(pd, axis=1), vb.std_mean(pd, axis=1),\n",
    "                 marker='.', label=str(size))\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups = 3\n",
    "num_nodes = 50\n",
    "order = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = 0.025 * 2 ** np.arange(11)\n",
    "list_num_steps = (num_nodes * (num_nodes * order + 1) * fractions).astype(int)\n",
    "list_num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_parameters():\n",
    "    # Generate group sizes and groups\n",
    "    density = np.random.dirichlet(100 * np.ones(num_groups)) # was 10 when things didn't work\n",
    "    z = np.random.choice(num_groups, num_nodes, p=density)\n",
    "    onehot = np.zeros((num_nodes, num_groups))\n",
    "    onehot[np.arange(num_nodes), z] = 1\n",
    "\n",
    "    # Sample noise precisions for all groups\n",
    "    noise_precision = np.random.gamma(5000, size=num_groups)\n",
    "    # noise_precision = 100\n",
    "\n",
    "    # Sample means and precisions of autoregressive coefficients\n",
    "    adjacency_mean = np.random.normal(0, 1e-2, size=(num_groups, num_groups, order))\n",
    "    adjacency_precision = scipy.stats.wishart.rvs(1e5, np.eye(order), size=(num_groups, num_groups))\n",
    "    if adjacency_precision.ndim < 4:\n",
    "        adjacency_precision = adjacency_precision.reshape((num_groups, num_groups, 1, 1))\n",
    "\n",
    "    # Sample the means and precisions of the bias\n",
    "    bias_mean = np.random.normal(0, 0.1, num_groups)\n",
    "    bias_precision = np.random.gamma(1e4, 1, num_groups)\n",
    "\n",
    "    # Sample the matrix of autoregressive coefficients\n",
    "    cholesky = np.linalg.cholesky(np.linalg.inv(adjacency_precision))\n",
    "    cholesky = cholesky[z[:, None], z[None, :]]\n",
    "    adjacency = adjacency_mean[z[:, None], z[None, :]] + \\\n",
    "        np.einsum('...ij,...j', cholesky, np.random.normal(0, 1, (num_nodes, num_nodes, order)))\n",
    "\n",
    "    # Sample the bias\n",
    "    bias = np.random.normal(0, 1, num_nodes) / np.sqrt(bias_precision[z]) + bias_mean[z]\n",
    "\n",
    "    # Construct the coefficients for comparison\n",
    "    coefficients = vb.pack_coefficients(adjacency, bias)\n",
    "    \n",
    "    return {\n",
    "        'coefficients': coefficients,\n",
    "        'bias': bias,\n",
    "        'adjacency': adjacency,\n",
    "        'z': z,\n",
    "        'noise_precision': noise_precision,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(*_, tqdm=False):\n",
    "    result = defaultdict(list)\n",
    "    parameters = simulate_parameters()\n",
    "    result['parameters'] = parameters\n",
    "    \n",
    "    for num_steps in tqdm_notebook(list_num_steps) if tqdm else list_num_steps:\n",
    "        series = vb.simulate_series(parameters['bias'], parameters['adjacency'], \n",
    "                                    parameters['noise_precision'][parameters['z']], int(num_steps))\n",
    "\n",
    "        factors = {\n",
    "            'coefficients': vb.MultiNormalDistribution(\n",
    "                np.zeros((num_nodes, num_nodes * order + 1)),\n",
    "                np.ones((num_nodes, 1, 1)) * np.eye(num_nodes * order + 1)\n",
    "            ),\n",
    "            'noise_precision': vb.GammaDistribution(\n",
    "                1e-3 * np.ones(num_nodes),\n",
    "                1e-3 * np.ones(num_nodes)\n",
    "            )\n",
    "        }\n",
    "        likelihoods = [\n",
    "            vb.VARDistribution(factors['coefficients'], factors['noise_precision']).likelihood(\n",
    "                vb.VARDistribution.summary_statistics(series, order)\n",
    "            ),\n",
    "            vb.GammaDistribution(1e-6, 1e-6).likelihood(factors['noise_precision']),\n",
    "            vb.MultiNormalDistribution(\n",
    "                np.zeros(num_nodes * order + 1), \n",
    "                np.eye(num_nodes * order + 1) * 1e-100\n",
    "            ).likelihood(factors['coefficients'])\n",
    "        ]\n",
    "\n",
    "        # Model without hierarchical structure\n",
    "        model = vb.Model(factors, likelihoods)\n",
    "        model.update(None, convergence_predicate=1e-3)\n",
    "        \n",
    "        # Model with hierarchical structure\n",
    "        model2 = vb.var_model(series, order, num_groups, shared_noise=False)\n",
    "        model2.update(None, convergence_predicate=1e-3)\n",
    "        \n",
    "        result['means'].append(model['coefficients'].mean)\n",
    "        result['stds'].append(model['coefficients'].std)\n",
    "        result['means2'].append(model2['coefficients'].mean)\n",
    "        result['stds2'].append(model2['coefficients'].std)\n",
    "        result['zs'].append(model2['z'].mean)\n",
    "        \n",
    "        \n",
    "    result = {key: np.asarray(value) if isinstance(value, list) else value for key, value in result.items()}\n",
    "    return result\n",
    "\n",
    "filename = 'var-sample-size.pickle'\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'rb') as fp:\n",
    "        results = pickle.load(fp)\n",
    "else:\n",
    "    num_runs = 12\n",
    "    results = []\n",
    "    for _ in tqdm_notebook(range(num_runs)):\n",
    "        results.append(main(tqdm=True))\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(results, fp)\n",
    "\n",
    "results = IterableAccessor(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [(ax1, ax2), (ax3, ax4)] = plt.subplots(2, 2, True)\n",
    "sigmas = 2\n",
    "\n",
    "for list_scores, label in zip([np.divide(results['means'], results['stds']),\n",
    "                               np.divide(results['means2'], results['stds2'])],\n",
    "                              ['VAR', 'HVAR']):\n",
    "    significiant = np.mean(np.abs(list_scores) > sigmas, (2, 3))\n",
    "    ax1.errorbar(fractions, np.mean(significiant, axis=0), np.std(significiant, axis=0) / np.sqrt(num_runs - 1),\n",
    "                 label=label)\n",
    "    \n",
    "list_coefficients = np.asarray(IterableAccessor(results['parameters'])['coefficients'])[:, None]\n",
    "for residuals in [np.subtract(results['means'], list_coefficients),\n",
    "                  np.subtract(results['means2'], list_coefficients)]:\n",
    "    rmse = np.sqrt(np.mean(residuals * residuals, axis=(2, 3)))\n",
    "    ax4.errorbar(fractions, np.mean(rmse, axis=0), np.std(rmse, axis=0) / np.sqrt(num_runs - 1))\n",
    "    \n",
    "list_nmis = []\n",
    "for parameters, zs in zip(results['parameters'], results['zs']):\n",
    "    nmis = [metrics.normalized_mutual_info_score(parameters['z'], np.argmax(z, axis=1)) for z in zs]\n",
    "    list_nmis.append(nmis)\n",
    "    \n",
    "ax3.errorbar(fractions, np.mean(list_nmis, axis=0), \n",
    "             np.std(list_nmis, axis=0) / np.sqrt(num_runs - 1), color='C1')\n",
    "\n",
    "for ax in [ax1, ax3, ax4]:\n",
    "    ax.axvline(1, ls=':', color='k')\n",
    "    \n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel(r'$\\mathrm{avg}\\left[\\left|\\frac{\\hat\\theta}{\\sigma}\\right| > 2\\right]$')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_axis_off()\n",
    "ax2.text(0, 1, \"$n=%d$\\n$p=%d$\\n$K=%d$\" % (num_nodes, order, num_groups), \n",
    "         transform=ax2.transAxes, va='top')\n",
    "\n",
    "ax3.set_xlabel('Fraction $f$')\n",
    "ax3.set_ylabel('NMI')\n",
    "\n",
    "ax4.set_xlabel('Fraction $f$')\n",
    "ax4.set_ylabel('RMSE')\n",
    "ax4.set_yscale('log')\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
